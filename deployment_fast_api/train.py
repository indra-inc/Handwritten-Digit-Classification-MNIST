# -*- coding: utf-8 -*-
"""Digit_Classification_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13sTwYrm6q8BqsLY2YScxI1FRb1P7byjN

# Project : Handwritten Digit Recognition
## Type : Multiclass Image Classification using Deep Learning
### Dataset : MNIST

## What is Handwritten Digit Recognition?
The handwritten digit recognition is the ability of computers to recognize human handwritten digits. It is a hard task for the machine because handwritten digits are not perfect and can be made with many different flavors. The handwritten digit recognition is the solution to this problem which uses the image of a digit and recognizes the digit present in the image.

## The MNIST dataset
This is probably one of the most popular datasets among machine learning and deep learning enthusiasts. The MNIST dataset contains 60,000 training images of handwritten digits from zero to nine and 10,000 images for testing. So, the MNIST dataset has 10 different classes. The handwritten digits images are represented as a 28Ã—28 matrix where each cell contains grayscale pixel value.

## S-1: Importing necessary dependecies
"""

# Commented out IPython magic to ensure Python compatibility.
## Importing necessary Lib
import numpy as np
import pandas as pd
import random
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
plt.style.use('dark_background')
import warnings
warnings.filterwarnings("ignore")
import matplotlib.image as mpimg
np.random.seed(42)  # for reproducibility

import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
import tensorflow as tf
import keras

# import the library needed for one hot encoding
from keras.utils import np_utils
from keras import backend as K
from keras.models import Sequential, load_model
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout
from tensorflow.keras.utils import img_to_array, load_img

from tensorflow.keras.optimizers import Adam
from keras.utils import plot_model
from sklearn.model_selection import train_test_split, KFold

## Load image data from MNIST
from keras.datasets import mnist

## S-2: Preprocess the data

## Loading our dataset and to get train valid and test dataset

def load_dataset():

    (X_train, Y_train), (x_test, y_test) = mnist.load_data()

    ## Spliting the traing dataset into traing and validation

    x_train, x_valid, y_train, y_valid = train_test_split(X_train, Y_train, test_size = 0.3, random_state = 77)
    # The number of training and testing images present in the dataset
    print('There are %d training images.' % len(x_train))
    print('There are %d valid images.' % len(x_valid))
    print('There are %d testing images.' % len(x_test))

    # printing shape of training dataset
    print('Shape of training, validation and test dataset before reshaping:', x_train.shape, x_valid.shape, x_test.shape) 

    print("Number of Train labels:",len(np.unique(y_train)))

    # unique values in y_train, y_valid and y_test
    print(np.unique(y_train))
    print(np.unique(y_valid))
    print(np.unique(y_test))

    # Reshape to be samples*pixels*width*height
    x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')
    x_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1).astype('float32')
    x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')

    # Printing the new dimensions
    print('Shape of training, validation and test dataset after reshaping:', x_train.shape, x_valid.shape, x_test.shape)

    # One hot Code
    y_train = np_utils.to_categorical(y_train)
    y_valid = np_utils.to_categorical(y_valid)
    y_test = np_utils.to_categorical(y_test)
    num_classes = y_test.shape[1]

    # normalize the pixel value to range [0, 1]
    x_train = (x_train / 255.0)
    x_valid = (x_valid / 255.0)
    x_test = (x_test / 255.0)

    return x_train, y_train, x_valid, y_valid, x_test, y_test


## S-3: Model Building


## Creating Model
def create_model():
  model_hr = Sequential(
      [
      Conv2D(
          32,
          kernel_size=(5, 5),
          padding="same",
          activation="relu",
          input_shape=(28, 28, 1),
      ),
      MaxPooling2D(pool_size=(2, 2)),
      Conv2D(64, kernel_size=(5, 5), padding="same", activation="relu"),
      MaxPooling2D(pool_size=(2, 2)),
      Dropout(0.25),
      Flatten(),
      Dense(128, activation="relu"),
      Dropout(0.3),
      Dense(64, activation="relu"),
      Dropout(0.5),
      Dense(10, activation="softmax"),
      ]
      )
  # Print the model summary
  model_hr.summary()

  # Compile model
  model_hr.compile(
      optimizer= Adam(),
      loss='categorical_crossentropy',
      metrics=["accuracy"]
  )
  return model_hr


## Plot graph
plot_model(model_hr, to_file='MNIST.png', show_shapes=True, show_layer_names=True)


## Fit model 
def fitModel(model, x_train,y_train , x_valid,y_valid):
  history = model.fit(
  x_train,
  y_train,
  batch_size=128,
  epochs=20,
  validation_data=(x_valid, y_valid),
  verbose = 1)
  print("The model has successfully trained")
  return history


# Plot the validation and training curves separately
def plot_loss_curves(history):
  """
  Returns separate loss curves for training and validation metrics.
  """
  loss = history.history["loss"]
  val_loss = history.history["val_loss"]

  accuracy = history.history["accuracy"]
  val_accuracy = history.history["val_accuracy"]

  epochs = range(len(history.history["loss"])) 

  # Plot loss
  plt.plot(epochs, loss, label="training_loss")
  plt.plot(epochs, val_loss, label="val_loss")
  plt.title("loss")
  plt.xlabel("epochs")
  plt.legend()

  # Plot accuracy
  plt.figure()
  plt.plot(epochs, accuracy, label="training_accuracy")
  plt.plot(epochs, val_accuracy, label="val_accuracy")
  plt.title("accuracy")
  plt.xlabel("epochs")
  plt.legend();


## Evaluate Model
def test_results(model,X, y):

  score = model.evaluate(X, y, verbose=1)
  # Create a dictionary of model results
  print('Test_loss:', score[0])
  print('Test_accuracy:', score[1])

## Save Model
def save_model(model):
  model.save('mnist.h5')
  print("Saving the model as mnist.h5")

## Evaluate Model
def test_results(model,X, y):
  
  score = model.evaluate(X, y, verbose=1)
  # Create a dictionary of model results
  print('Test_loss:', score[0])
  print('Test_accuracy:', score[1])


